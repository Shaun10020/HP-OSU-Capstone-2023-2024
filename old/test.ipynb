{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config.args import get_arguments\n",
    "from config.config import features,labels,duplex_labels,train_test_ratio,label_extension,threshold, train_val_ratio, random\n",
    "from dataloader.load_data import SimplexDataset, DuplexDataset, InputSimplexDataset, InputDuplexDataset, load_dataloader\n",
    "from utils.load_json import load_results\n",
    "from utils.save_load_model import load\n",
    "from utils.convert import convertBinary\n",
    "from utils.metrics import binary_iou\n",
    "from utils.output_viz import print_output\n",
    "from model.UNet import UNet, CustomUNet1\n",
    "from model.ENet import ENet, CustomENet1\n",
    "from model.DeepLabV3 import CustomDeepLabV3\n",
    "from train.train import Train\n",
    "from train.test import Test\n",
    "\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataset):\n",
    "    if random:\n",
    "        train_set, test_set = random_split(dataset,train_test_ratio,torch.Generator())\n",
    "    else:\n",
    "        train_size = len(dataset)*train_test_ratio[0]\n",
    "        train_set = Subset(dataset,range(int(train_size)))\n",
    "        test_set = Subset(dataset,range(int(train_size),len(dataset)))\n",
    "    filepath = os.path.join(args.save_folder,f'''{args.model}-{args.dataset}.pt''')\n",
    "    if os.path.exists(filepath):\n",
    "        model = load(model,args)\n",
    "    train = Train(model,device,train_set,args)\n",
    "    train.run()\n",
    "    \n",
    "    model = load(model,args)\n",
    "    test = Test(model,device,test_set,int(args.batch),args)\n",
    "    test.run()\n",
    "    \n",
    "    train.save_plot()\n",
    "\n",
    "def test(model,dataset):\n",
    "    model = load(model,args)\n",
    "    test = Test(model,device,dataset,int(args.batch),args)\n",
    "    test.run()\n",
    "\n",
    "def inference(model):\n",
    "    if not os.path.exists(args.output_folder):\n",
    "        os.mkdir(args.output_folder)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    if args.dataset == \"simplex\":\n",
    "        data = InputSimplexDataset(args)\n",
    "    elif args.dataset == \"duplex\":\n",
    "        data = InputDuplexDataset(args)\n",
    "    loader = DataLoader(data,batch_size = int(args.batch))\n",
    "    \n",
    "    json_name = \"\"\n",
    "    intermediate = []\n",
    "    for batch in loader:\n",
    "        input = batch[2].to(device)\n",
    "        outputs = model(input.float())\n",
    "        outputs = convertBinary(outputs)\n",
    "        for name,pn,output in zip(batch[0],batch[1],outputs):\n",
    "            if not json_name:\n",
    "                json_name = name\n",
    "            if json_name != name:\n",
    "                fp = open(os.path.join(args.output_folder,json_name,\"results.json\"),\"w\")\n",
    "                json.dump({\"intermediate_results\":intermediate},fp)\n",
    "                fp.close()\n",
    "                json_name = name\n",
    "                intermediate = []\n",
    "            pn = pn.item()\n",
    "            pgnum = (4-len(str(pn)))*\"0\" + str(pn)\n",
    "            json_instance = {\"pdf_filename\":name+\".pdf\",\"page_num\":pn,\"intermediate_dir\":\"intermediate_results/\"+pgnum}\n",
    "            path = os.path.join(args.output_folder,name)\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            path = os.path.join(path,\"intermediate_results\")\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            if args.dataset == \"simplex\":\n",
    "                path = os.path.join(path,pgnum)\n",
    "                if not os.path.exists(path):\n",
    "                    os.mkdir(path)\n",
    "                for i, label in enumerate(labels):\n",
    "                    to_pil_image(output[i]).save(os.path.join(path,f'''{label}{label_extension}'''))\n",
    "                    json_instance[label] = json_instance[\"intermediate_dir\"]+\"/\"+str(label)+str(label_extension)\n",
    "                intermediate.append(json_instance)\n",
    "            \n",
    "            elif args.dataset == \"duplex\":\n",
    "                pgnum2 = (4-len(str(pn)))*\"0\" + str(pn+1)\n",
    "                json_instance2 = {\"pdf_filename\":name+\".pdf\",\"page_num\":pn+1,\"intermediate_dir\":\"intermediate_results/\"+pgnum2}\n",
    "                path2 = os.path.join(path,pgnum2)\n",
    "                path = os.path.join(path,pgnum)\n",
    "                if not os.path.exists(path):\n",
    "                    os.mkdir(path)\n",
    "                if not os.path.exists(path2):\n",
    "                    os.mkdir(path2)\n",
    "                cur = 0\n",
    "                for i, label in enumerate(labels):\n",
    "                    to_pil_image(output[cur + i]).save(os.path.join(path,f'''{label}{label_extension}'''))\n",
    "                    json_instance[label] = json_instance[\"intermediate_dir\"]+\"/\"+str(label)+str(label_extension)\n",
    "                cur += len(labels)\n",
    "                for i, label in enumerate(duplex_labels):\n",
    "                    to_pil_image(output[cur + i]).save(os.path.join(path,f'''{label}{label_extension}'''))\n",
    "                    json_instance[label] = json_instance[\"intermediate_dir\"]+\"/\"+str(label)+str(label_extension)\n",
    "                cur += len(duplex_labels)\n",
    "                for i, label in enumerate(labels):\n",
    "                    to_pil_image(output[cur + i]).save(os.path.join(path2,f'''{label}{label_extension}'''))\n",
    "                    json_instance2[label] = json_instance2[\"intermediate_dir\"]+\"/\"+str(label)+str(label_extension)\n",
    "                intermediate.append(json_instance)\n",
    "                intermediate.append(json_instance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class default:\n",
    "    def __init__(self):\n",
    "        self.input_folder = \"./data/cache/DP_a2200_xml_ff2c81d8ad6655f915cbaa558ee7bf9e878730a8\"\n",
    "        self.output_folder = \"./output_unet_simplex\"\n",
    "        self.label_folder = \"./data/output/DP_a2200_xml_ff2c81d8ad6655f915cbaa558ee7bf9e878730a8\"\n",
    "        self.save_folder = \"./checkpoints\"\n",
    "        self.model = \"enet\"\n",
    "        self.mode = \"test\"\n",
    "        self.epoch = 300\n",
    "        self.lr = 1e-5\n",
    "        self.lr_decay = 0.1\n",
    "        self.lr_epoch = 50\n",
    "        self.batch = 5\n",
    "        self.dataset = \"simplex\"\n",
    "        \n",
    "class WeightedBinaryLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, w_p = None, w_n = None):\n",
    "        super(WeightedBinaryLoss, self).__init__()\n",
    "        self.w_p = w_p\n",
    "        self.w_n = w_n\n",
    "        \n",
    "    def forward(self, inputs, labels, epsilon = 1e-7):\n",
    "        loss_pos = -1 * torch.mean(self.w_p * labels * torch.log(inputs + epsilon))\n",
    "        loss_neg = -1 * torch.mean(self.w_n * (1-labels) * torch.log((1-inputs) + epsilon))\n",
    "        loss = loss_pos + loss_neg\n",
    "        return loss\n",
    "        \n",
    "args = default()\n",
    "criterion = WeightedBinaryLoss(w_p = 2.0,w_n = 2.0)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logging.info(f'''Using device: {device}''')\n",
    "\n",
    "n_input = len(features) if args.dataset == 'simplex' else 2*len(features)\n",
    "n_output = len(labels) if args.dataset == 'simplex' else 2*len(labels)+len(duplex_labels)\n",
    "if args.mode != 'inference':\n",
    "    pdf,algorithm,intermediate = load_results(args.label_folder)\n",
    "    if args.dataset =='simplex':\n",
    "        dataset = SimplexDataset(args.input_folder,args.label_folder,intermediate)\n",
    "    else:\n",
    "        dataset = DuplexDataset(args.input_folder,args.label_folder,intermediate)\n",
    "        \n",
    "if args.model == 'unet':\n",
    "    model = UNet(n_input,n_output)\n",
    "elif args.model == 'enet':\n",
    "    model = ENet(n_input,n_output)\n",
    "elif args.model == 'deeplabv3':\n",
    "    model = CustomDeepLabV3(n_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model,args)\n",
    "test = Test(model,device,dataset,int(args.batch),args)\n",
    "\n",
    "\n",
    "logging.info(\"Running testing script...\")\n",
    "test.model.eval()\n",
    "epoch_loss = 0.0\n",
    "IoU = 0.0\n",
    "for batch_data in tqdm(test.test_dataloader):\n",
    "    inputs, labels = batch_data[0].to(test.device), batch_data[1].to(test.device)\n",
    "    preds = test.model(inputs.float())\n",
    "    loss = test.criterion(preds,labels)\n",
    "    epoch_loss += loss.item()\n",
    "    IoU += binary_iou(labels,convertBinary(preds))\n",
    "    print_output(0,labels,convertBinary(preds))\n",
    "logging.info(f'''Test Loss: {epoch_loss / len(test.test_dataloader):.4f}''')\n",
    "logging.info(f'''Test IoU: {IoU / len(test.test_dataloader)* 100:.2f}%''')\n",
    "logging.info(\"Done running testing script...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
